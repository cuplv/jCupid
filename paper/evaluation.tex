

We evaluated jCupid using a set of simple programs that commonly contain timing
side channels in their implementations.


\paragraph{Password checking}
The na\"{\i}ve method of checking whether a provided password is correct is to iterate
over the provided input, comparing each character to its expected value, and
returning failure on the first discovered difference. This results in a side
channel that leaks the number of characters that an attacker has guessed
correctly, allowing them to perform an adaptive attack. The attacker can guess
each character independently, and only move on to the next character when they
have found the correct character in the current position. While we call this a
password checking test case, this pattern also occurs in any string comparison
that should be done in constant time, such as when checking if CSRF or
authentication tokens are valid.

%\paragraph{Lucky-13 attack}
%We implemented a toy Java version of the padding and MAC check employed in TLS
%decryption. Our implementation was vulnerable to the Lucky 13 attack, where
%an attacker modifies ciphertext, and can distinguish between the corresponding
%plaintext having valid padding or not. This capability allows an attacker to
%perform a Vaudenay attack and iteratively leak the plaintext.

\paragraph{Modular Exponentiation}
We implemented the straightforward method for modular exponentiation shown in
Algorithm~\ref{alg:expo}. This algorithm has a side-channel dependent on the
(private) exponent input. To compare against a side-channel-free version,
we also implemented a variant on the Montgomery Ladder
technique for modular exponentiation. However, we had to use algebric tricks to
replace the branches that are present in the algorithm. Our updated version has no
data-dependent branches, and relies only on multiplication, addition,
subtraction, and modulo.


\paragraph{SumBytes}
We created a program that reads a single byte to determine a length, then reads
that many bytes and hashes them. Here, we are mimicking a simple serialized
network protocol with a length encoded at the beginning of the message. The side
channel present in this code is subtle: there are no if statements or obvious
branches in the code. Rather, the number of bytes read determines the number of
compression function iterations occur internal to our hash function.

\paragraph{Multiplexer}
Finally, we implemented a selection function that takes three inputs: a, b, and
a selector. If the selector is true, our function returns the first input,
otherwise it returns the second input. This is easily accomplished by an if
statement, however, such an implementation may leak information due to instruction cache timing or
memory accesses.



For each of these programs, we allowed them to take a single input as a string
on standard input. Then, we allowed \jcupid to fuzz these programs with random
inputs, and look for potential differences in the bytecodes executed. In each
example, we found the intended side-channel, and \jcupid was able to correctly
determine the line of code responsible.

We then corrected the problems identified by \jcupid, and reran our tool to
verify we had removed the offending side-channels. To our surprise, \jcupid
identified additional problems in some of our ``corrected'' programs. For example, in
the password checking program, we used a temporary value, and updated it at each
iteration with $ good \&= (input[i] == expected[i]) $. However, this resulted in
a side-channel when computing the $ == $ operator, as Java implemented this as a
branch in the bytecode. We fixed this by switching to using exclusive-or to
compare the values, and \jcupid did not detect any additional side-channels. This
further illustrates the difficulty of removing all potential side-channels from
code: even seemingly branch-free programs, written with the intention of not
having side-channels, can contain them.


As \jcupid is a dynamic analysis tool, it must run many instances of the program
in order to find side-channel behavior. We evaluated \jcupid's overhead by
measuring how quickly it can run basic Java programs, and compared it to
running those same programs outside of the \jcupid environment. Particularly for
a developer dynamic analysis tool that inspects individual bytecodes, our
results are encouraging: per run, \jcupid only adds on average approximatly 2x
overhead. This could allow even rare side-channels to be detected with
na\"{\i}ve fuzzing of nightly builds over unit tests.

\paragraph{Timing experimentation}
In order to test the efficiency of \jcupid, we ran a number of experiments to
determine how much overhead \jcupid has, and where the overhead comes from.
With the above test programs, we ran each program 10 times with an unmodified
OpenJDK. Then, we ran each program using our tool with 10 iterations. Over all
of the runs, we found that stock OpenJDK took on average 2.6 seconds per
iteration, while \jcupid took on average 5.3 seconds per iteration. However, this
is obviously variable based on the input program: for longer running and more
computationally-expensive programs, \jcupid's overhead is lower.

To determine which components of \jcupid are responsible for its overhead, we
removed individual components and reran our programs. We ran our python tool in
a way that it called a normal OpenJDK rather than our modified (debug) one, and
found that it took on average 3.6 seconds per run. We then ran our tool using a
modified version of OpenJDK that did not use hashing, and found it takes 4.8
seconds. Thus, we estimate that our python tool adds about half of the overhead
of \jcupid,
with the remainder coming mainly from the debug version of OpenJDK, and a small
contribution from the fast hash function itself.

%with the inputs. Then we ran the programs with a modified version of our tool 
%which simply calls OpenJDK, with no flags -- this allows us to test how much 
%overhead the tool itself has. Finally we run the tool on a modified OpenJDK such
%that the hash function does no work (meaning nothing will be flagged) -- this 
%tells us how much time our hash function is taking. Each of the above tests are 
%run 5 times.
%
%Averaging the time results across the different programs provides the following
%results: just calling OpenJDK takes around 2.6 seconds, \jcupid averages 5.3 seconds
%per call to OpenJDK. This is an overhead of 2.7 seconds. The following two results
%will help us determine where this overhead comes from. With the modified jCupid tool
%that just calls OpenJDK with no flags takes 3.6 seconds, and finally calling jCupid
%that calls a modified OpenJDK that does not do hashing takes 4.8 seconds.
%
%The above results tell us that of the 2.7 seconds of overhead 1.0 seconds of overhead
%come from the tool itself, and 1.2 second of overhead comes from the flags that
%we use in jCupid. Thus the remaining 0.5 seconds of overhead come from the hash
%function itself.
